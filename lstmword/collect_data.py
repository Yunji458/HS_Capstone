import cv2
import os
import time
import random
import numpy as np
from scipy.interpolate import interp1d
from scipy.spatial.transform import Rotation as R_scipy
import mediapipe as mp
from tqdm import tqdm
import copy

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì„¤ì •ê°’ (ê¸°ë³¸) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
NUM_FRAMES = 30
NUM_KEYPOINTS = 1 + 21 + 21 # ì½”(1) + ì™¼ì†(21) + ì˜¤ë¥¸ì†(21) = 43
NUM_COORDS = 3
TARGET_SHAPE = (NUM_FRAMES, NUM_KEYPOINTS * NUM_COORDS) # (30, 129)
IS_HAND_INACTIVE_THRESHOLD = 1e-5 # ì† ë¹„í™œì„± íŒë‹¨ ì„ê³„ê°’

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ìƒˆë¡œìš´ ì¦ê°• íŒŒë¼ë¯¸í„° (v2) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
# 1. ê° ì–‘ì† 3D íšŒì „
HAND_ROTATION_DEG_RANGE_INDIVIDUAL = (-15, 15) # ê° ì¶•ë³„ íšŒì „ ë²”ìœ„ (ë„)

# 2. ê° ì–‘ì† ë…ë¦½ì  ì´ë™
HAND_TRANSLATE_X_RANGE_INDIVIDUAL = (-0.03, 0.03)
HAND_TRANSLATE_Y_RANGE_INDIVIDUAL = (-0.03, 0.03)
HAND_TRANSLATE_Z_RANGE_INDIVIDUAL = (-0.02, 0.02) # zëŠ” 0.005 ë¶€í„° -0.01 (min, max ìˆœì„œë¡œ)

# 3. ì–‘ì† í•¨ê»˜ ì´ë™ (ì½” ê¸°ì¤€ ìƒëŒ€ ìœ„ì¹˜ ìœ ì§€í•˜ë©°)
HAND_TRANSLATE_X_RANGE_TOGETHER = (-0.1, 0.1)
HAND_TRANSLATE_Y_RANGE_TOGETHER = (-0.1, 0.1)
HAND_TRANSLATE_Z_RANGE_TOGETHER = (-0.02, 0.02) # zëŠ” 0.01 ë¶€í„° -0.02 (min, max ìˆœì„œë¡œ)

# 4. ë…¸ì´ì¦ˆ
KEYPOINT_JITTER_SIGMA_RANGE_V2 = (0.003, 0.005) # ê¸°ì¡´ ê°’ ì¬í™œìš© ë˜ëŠ” ì¡°ì •

# 5. ì† í¬ê¸°
HAND_SCALE_RANGE_V2 = (0.8, 1.2) # ê¸°ì¡´ ê°’ ì¬í™œìš© ë˜ëŠ” ì¡°ì •

# 6. ì†ê°€ë½ ê¸¸ì´
FINGER_LENGTH_SCALE_RANGE_V2 = (0.8, 1.2) # ê¸°ì¡´ ê°’ ì¬í™œìš© ë˜ëŠ” ì¡°ì •

# 7. ì „ì²´ ìŠ¤ì¼€ì¼
OVERALL_SCALE_RANGE = (0.5, 1.2)

# 8. ì‹œì  ë³€í™” ì„¤ì •
VIEW_CONFIGS_RANDOM_V2 = {
    "frontal":    { "yaw_range": (-10, 10), "pitch_range": (-10, 10), "num_augs_total": 500 }, # ì˜ˆì‹œ: ì •ë©´ ì¦ê°• ìˆ˜
    "left_bias":  { "yaw_range": (35, 55),  "pitch_range": (-10, 10), "num_augs_total": 500 }, # ì˜ˆì‹œ: ê° ë°©í–¥ ì¦ê°• ìˆ˜
    "right_bias": { "yaw_range": (-55, -35),"pitch_range": (-10, 10), "num_augs_total": 500 },
    "up_bias":    { "yaw_range": (-10, 10), "pitch_range": (-55, -35),"num_augs_total": 500 },
    "down_bias":  { "yaw_range": (-10, 10), "pitch_range": (35, 55),  "num_augs_total": 500 },
}
# ì´ ì¦ê°• ëª©í‘œ ìˆ˜ (ì˜ˆì‹œ, í•„ìš”ì‹œ VIEW_CONFIGS_RANDOM_V2ì˜ num_augs_total í•©ìœ¼ë¡œ ê³„ì‚°)
# NUM_TOTAL_AUG_TARGET_V2 = 600 # ì´ ê°’ì€ ìœ„ configì˜ í•©ìœ¼ë¡œ ê²°ì •ë¨

# --- ì €ì¥ ê²½ë¡œ ---
ORIGINAL_DATASET_PATH = 'dataset_original_NoseHands_final_v3_newaug' # ê²½ë¡œ ë³€ê²½
AUGMENTED_DATASET_PATH = 'dataset_augmented_NoseHands_final_v3_newaug' # ê²½ë¡œ ë³€ê²½

# --- Mediapipe ì„¤ì • ---
mp_holistic = mp.solutions.holistic
mp_drawing = mp.solutions.drawing_utils
holistic = mp_holistic.Holistic(static_image_mode=False, model_complexity=1,
                               min_detection_confidence=0.5, min_tracking_confidence=0.5)

# --- í‚¤í¬ì¸íŠ¸ ì¸ë±ìŠ¤ (43ê°œ ê¸°ì¤€) ---
POSE_ID_NOSE = mp_holistic.PoseLandmark.NOSE.value
NOSE_IDX = 0
LEFT_HAND_START_IDX = 1
RIGHT_HAND_START_IDX = 1 + 21
HAND_KEYPOINTS_COUNT = 21

WINDOW_NAME = "ìˆ˜ì–´ ë°ì´í„° ìˆ˜ì§‘ (ì½”+ì–‘ì†, ì‹ ê·œì¦ê°• v3)"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ ë° ë³´ê°„ (ê¸°ì¡´ê³¼ ë™ì¼) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
def extract_keypoints(res):
    def get_pose_landmark_nose():
        if res.pose_landmarks and res.pose_landmarks.landmark:
            try: lm = res.pose_landmarks.landmark[POSE_ID_NOSE]; return np.array([lm.x, lm.y, lm.z])
            except IndexError: return np.zeros(NUM_COORDS)
        return np.zeros(NUM_COORDS)
    def get_hand_landmarks(hand_landmarks_mp):
        if hand_landmarks_mp and hand_landmarks_mp.landmark:
            return np.array([[lm.x, lm.y, lm.z] for lm in hand_landmarks_mp.landmark])
        return np.zeros((HAND_KEYPOINTS_COUNT, NUM_COORDS))
    nose = get_pose_landmark_nose()
    l_hand = get_hand_landmarks(res.left_hand_landmarks)
    r_hand = get_hand_landmarks(res.right_hand_landmarks)
    return np.concatenate([[nose], l_hand, r_hand]).flatten()

def interpolate_zeros(seq_flat):
    seq_interpolated = seq_flat.copy()
    for dim_idx in range(seq_interpolated.shape[1]):
        col = seq_interpolated[:, dim_idx].copy()
        nz_indices = np.nonzero(col)[0]
        if len(nz_indices) == 0: continue
        elif len(nz_indices) == 1:
            seq_interpolated[:, dim_idx] = col[nz_indices[0]]
            continue
        first_nz_idx, last_nz_idx = nz_indices[0], nz_indices[-1]
        interp_func = interp1d(
            nz_indices, col[nz_indices],
            kind='linear', bounds_error=False,
            fill_value=(col[first_nz_idx], col[last_nz_idx])
        )
        all_indices = np.arange(len(col))
        seq_interpolated[:, dim_idx] = interp_func(all_indices)
    return seq_interpolated

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ìƒˆë¡œìš´ ì¦ê°• í•¨ìˆ˜ë“¤ (v2) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #

def aug_rotate_hands_independently_v2(kps_3d_in, deg_range, is_left_active, is_right_active):
    kps_3d = kps_3d_in.copy()
    hand_info = [(LEFT_HAND_START_IDX, is_left_active), (RIGHT_HAND_START_IDX, is_right_active)]
    for hand_offset, is_active in hand_info:
        if is_active:
            # ê° ì†ì— ëŒ€í•´ ë…ë¦½ì ì¸ ëœë¤ íšŒì „ ê°ë„ ìƒì„±
            rand_angles_deg = np.random.uniform(deg_range[0], deg_range[1], 3) # x, y, z ì¶• íšŒì „
            rotation_matrix = R_scipy.from_euler('xyz', rand_angles_deg, degrees=True).as_matrix()
            
            wrist_kps_seq = kps_3d[:, hand_offset, :].copy() # (T, 3)
            hand_kps_seq = kps_3d[:, hand_offset : hand_offset + HAND_KEYPOINTS_COUNT, :].copy() # (T, 21, 3)
            
            # ì†ëª©ì„ ì¤‘ì‹¬ìœ¼ë¡œ íšŒì „
            hand_kps_rel_to_wrist_seq = hand_kps_seq - wrist_kps_seq[:, np.newaxis, :] # (T, 21, 3)
            rotated_hand_kps_rel_seq = np.einsum('ij,tkj -> tki', rotation_matrix, hand_kps_rel_to_wrist_seq) # (T, 21, 3)
            
            kps_3d[:, hand_offset : hand_offset + HAND_KEYPOINTS_COUNT, :] = rotated_hand_kps_rel_seq + wrist_kps_seq[:, np.newaxis, :]
    return kps_3d

def aug_translate_hands_independently_v2(kps_3d_in, x_range, y_range, z_range, is_left_active, is_right_active):
    kps_3d = kps_3d_in.copy()
    hand_info = [(LEFT_HAND_START_IDX, is_left_active), (RIGHT_HAND_START_IDX, is_right_active)]
    for hand_offset, is_active in hand_info:
        if is_active:
            # ê° ì†ì— ëŒ€í•´ ë…ë¦½ì ì¸ ëœë¤ ì´ë™ëŸ‰ ìƒì„±
            dx = random.uniform(*x_range)
            dy = random.uniform(*y_range)
            dz = random.uniform(*z_range)
            translation_vector = np.array([dx, dy, dz])
            
            kps_3d[:, hand_offset : hand_offset + HAND_KEYPOINTS_COUNT, :] += translation_vector[None, None, :]
    return kps_3d

def aug_translate_both_hands_together_v2(kps_3d_in, x_range, y_range, z_range, is_left_active, is_right_active):
    kps_3d = kps_3d_in.copy()
    # ì–‘ì†ì— ë™ì¼í•˜ê²Œ ì ìš©ë  í•˜ë‚˜ì˜ ëœë¤ ì´ë™ëŸ‰ ìƒì„±
    dx = random.uniform(*x_range)
    dy = random.uniform(*y_range)
    dz = random.uniform(*z_range)
    translation_vector = np.array([dx, dy, dz])
    
    if is_left_active:
        kps_3d[:, LEFT_HAND_START_IDX : LEFT_HAND_START_IDX + HAND_KEYPOINTS_COUNT, :] += translation_vector[None, None, :]
    if is_right_active:
        kps_3d[:, RIGHT_HAND_START_IDX : RIGHT_HAND_START_IDX + HAND_KEYPOINTS_COUNT, :] += translation_vector[None, None, :]
    # ì½”ëŠ” ì´ë™í•˜ì§€ ì•ŠìŒ
    return kps_3d

def aug_add_noise_v2(kps_3d_in, sigma_range, is_left_active, is_right_active):
    kps_3d = kps_3d_in.copy()
    sigma = random.uniform(*sigma_range)
    noise = np.random.normal(0, sigma, kps_3d.shape)
    
    # ì½”ì—ëŠ” í•­ìƒ ë…¸ì´ì¦ˆ ì ìš©
    kps_3d[:, NOSE_IDX, :] += noise[:, NOSE_IDX, :]
    if is_left_active:
        kps_3d[:, LEFT_HAND_START_IDX : LEFT_HAND_START_IDX + HAND_KEYPOINTS_COUNT, :] += \
            noise[:, LEFT_HAND_START_IDX : LEFT_HAND_START_IDX + HAND_KEYPOINTS_COUNT, :]
    if is_right_active:
        kps_3d[:, RIGHT_HAND_START_IDX : RIGHT_HAND_START_IDX + HAND_KEYPOINTS_COUNT, :] += \
            noise[:, RIGHT_HAND_START_IDX : RIGHT_HAND_START_IDX + HAND_KEYPOINTS_COUNT, :]
    return kps_3d

def aug_scale_hands_v2(kps_3d_in, scale_range, is_left_active, is_right_active):
    kps_3d = kps_3d_in.copy()
    scale_factor = random.uniform(*scale_range) # ì–‘ì†ì— ë™ì¼í•œ ìŠ¤ì¼€ì¼ íŒ©í„° ì ìš© (ì¼ê´€ì„±)
    
    hand_info = [(LEFT_HAND_START_IDX, is_left_active), (RIGHT_HAND_START_IDX, is_right_active)]
    for hand_offset, is_active in hand_info:
        if is_active:
            wrist_kps_seq = kps_3d[:, hand_offset, :] # (T, 3)
            for i in range(1, HAND_KEYPOINTS_COUNT): # ì†ëª© ì œì™¸í•œ ë‚˜ë¨¸ì§€ ì†ê°€ë½ ê´€ì ˆ
                kp_idx = hand_offset + i
                vec_from_wrist_seq = kps_3d[:, kp_idx, :] - wrist_kps_seq # (T, 3)
                kps_3d[:, kp_idx, :] = wrist_kps_seq + vec_from_wrist_seq * scale_factor
    return kps_3d

def aug_scale_finger_lengths_v2(kps_3d_in, scale_range, is_left_active, is_right_active):
    kps_3d = kps_3d_in.copy()
    # ì†ê°€ë½ ë§ˆë””ë³„ë¡œ ë‹¤ë¥¸ scale factorë¥¼ ì ìš©í•  ìˆ˜ë„ ìˆìœ¼ë‚˜, ì—¬ê¸°ì„œëŠ” ì† ì „ì²´ì— í•˜ë‚˜ì˜ factor ì ìš©
    # ì¢€ ë” ë³µì¡í•˜ê²Œ í•˜ë ¤ë©´, ê° ì†ê°€ë½ ê·¸ë£¹(ì˜ˆ: ì—„ì§€, ê²€ì§€ ë“±)ë³„ë¡œ ë‹¤ë¥¸ scale_factorë¥¼ ì ìš©í•  ìˆ˜ ìˆìŒ
    # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•˜ê²Œ ì†ëª©ì—ì„œ ê° ì†ê°€ë½ ëì ê¹Œì§€ì˜ ë²¡í„°ë¥¼ ìŠ¤ì¼€ì¼ë§
    scale_factor = random.uniform(*scale_range) # ì–‘ì†ì— ë™ì¼í•œ ìŠ¤ì¼€ì¼ íŒ©í„° ì ìš©

    hand_info = [(LEFT_HAND_START_IDX, is_left_active), (RIGHT_HAND_START_IDX, is_right_active)]
    for hand_offset, is_active in hand_info:
        if is_active:
            wrist_kps_seq = kps_3d[:, hand_offset, :] # (T, 3)
            # ì†ê°€ë½ ëì ë“¤ (MCP ì œì™¸, ë‹¨ìˆœí™” ìœ„í•´ ëª¨ë“  ì ì— ì ìš©)
            for i in range(1, HAND_KEYPOINTS_COUNT): # ì†ëª©(0) ì œì™¸
                finger_kp_idx = hand_offset + i
                vec_from_wrist_seq = kps_3d[:, finger_kp_idx, :] - wrist_kps_seq
                kps_3d[:, finger_kp_idx, :] = wrist_kps_seq + vec_from_wrist_seq * scale_factor
    return kps_3d

def aug_scale_overall_v2(kps_3d_in, scale_range, center_kp_idx=NOSE_IDX):
    kps_3d = kps_3d_in.copy()
    scale_factor = random.uniform(*scale_range)
    
    # ê¸°ì¤€ì  (ì˜ˆ: ì²« í”„ë ˆì„ì˜ ì½” ìœ„ì¹˜)
    # ì‹œí€€ìŠ¤ ì „ì²´ì— ê±¸ì³ ì¼ê´€ëœ ê¸°ì¤€ì ì„ ì‚¬ìš©í•˜ê±°ë‚˜, ê° í”„ë ˆì„ë³„ ì½”ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•  ìˆ˜ ìˆìŒ.
    # ì—¬ê¸°ì„œëŠ” ì²« í”„ë ˆì„ ì½”ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•¨ (ë” ì•ˆì •ì )
    center_of_scaling = kps_3d[0, center_kp_idx, :].copy() # (3,)
    
    # ëª¨ë“  í‚¤í¬ì¸íŠ¸ë¥¼ scaling_center ê¸°ì¤€ìœ¼ë¡œ ë³€í™˜
    kps_centered_seq = kps_3d - center_of_scaling[None, None, :] # (T, N_kp, 3)
    
    # ìŠ¤ì¼€ì¼ë§ ì ìš©
    kps_scaled_seq = kps_centered_seq * scale_factor
    
    # ë‹¤ì‹œ ì›ë˜ ìœ„ì¹˜ë¡œ ì´ë™
    kps_3d_scaled = kps_scaled_seq + center_of_scaling[None, None, :]
    return kps_3d_scaled

def aug_change_viewpoint_v2(kps_3d_in, yaw_deg, pitch_deg, center_kp_idx=NOSE_IDX):
    kps_3d = kps_3d_in.copy()
    
    # íšŒì „ ì¤‘ì‹¬ (ì˜ˆ: ì²« í”„ë ˆì„ì˜ ì½” ìœ„ì¹˜)
    center_of_rotation = kps_3d[0, center_kp_idx, :].copy() # (3,)
    
    # íšŒì „ í–‰ë ¬ ìƒì„± (Yaw ë¨¼ì €, ê·¸ ë‹¤ìŒ Pitch)
    rotation_matrix = R_scipy.from_euler('yx', [yaw_deg, pitch_deg], degrees=True).as_matrix()
    
    # ëª¨ë“  í‚¤í¬ì¸íŠ¸ë¥¼ íšŒì „ ì¤‘ì‹¬ìœ¼ë¡œ ì´ë™
    kps_centered_seq = kps_3d - center_of_rotation[None, None, :] # (T, N_kp, 3)
    
    # íšŒì „ ì ìš©: (T, N_kp, 3) x (3,3) -> (T, N_kp, 3)
    # np.einsum('tkj,ji->tki', kps_centered_seq, rotation_matrix.T) ì™€ ë™ì¼
    # ë˜ëŠ” np.einsum('ij,tkj->tki', rotation_matrix, kps_centered_seq)
    kps_rotated_seq = np.einsum('ij,tkj->tki', rotation_matrix, kps_centered_seq)

    # ë‹¤ì‹œ ì›ë˜ ìœ„ì¹˜(íšŒì „ í›„ ê¸°ì¤€ì )ë¡œ ì´ë™
    kps_3d_view_changed = kps_rotated_seq + center_of_rotation[None, None, :]
    return kps_3d_view_changed

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë©”ì¸ ì¦ê°• íŒŒì´í”„ë¼ì¸ (v2) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
def generate_augmentations_v2(original_sequence_flat, view_configs):
    original_kps_3d_abs = original_sequence_flat.reshape(NUM_FRAMES, NUM_KEYPOINTS, NUM_COORDS)
    augmented_sequences_list = []

    # --- ì›ë³¸ ë°ì´í„° ê¸°ì¤€ "í™œì„± ì†" íŒë‹¨ ---
    original_l_hand_data = original_kps_3d_abs[:, LEFT_HAND_START_IDX : LEFT_HAND_START_IDX + HAND_KEYPOINTS_COUNT, :]
    original_r_hand_data = original_kps_3d_abs[:, RIGHT_HAND_START_IDX : RIGHT_HAND_START_IDX + HAND_KEYPOINTS_COUNT, :]
    is_left_active_orig = np.mean(np.abs(original_l_hand_data)) > IS_HAND_INACTIVE_THRESHOLD
    is_right_active_orig = np.mean(np.abs(original_r_hand_data)) > IS_HAND_INACTIVE_THRESHOLD
    print(f"  ì›ë³¸ í™œì„± ì†: ì™¼ì†={is_left_active_orig}, ì˜¤ë¥¸ì†={is_right_active_orig}")

    total_augs_generated = 0
    for view_name, config in view_configs.items():
        num_augs_for_this_view = config.get("num_augs_total", 10) # ê° view typeë³„ ìƒì„± ìˆ˜
        if num_augs_for_this_view == 0: continue
        print(f"  '{view_name}' ì‹œì  ì¦ê°• ìƒì„± ì¤‘ ({num_augs_for_this_view}ê°œ)...")

        for _ in tqdm(range(num_augs_for_this_view), desc=f"{view_name} ì¦ê°•", unit="ìƒ˜í”Œ", leave=False):
            current_kps_3d = copy.deepcopy(original_kps_3d_abs)

            # ìˆœì°¨ì  ì¦ê°• ì ìš©
            # 1. ê° ì–‘ì† 3D íšŒì „
            current_kps_3d = aug_rotate_hands_independently_v2(current_kps_3d, HAND_ROTATION_DEG_RANGE_INDIVIDUAL, is_left_active_orig, is_right_active_orig)
            
            # 2. ê° ì–‘ì† ë…ë¦½ì  ì´ë™
            current_kps_3d = aug_translate_hands_independently_v2(current_kps_3d, 
                                                                HAND_TRANSLATE_X_RANGE_INDIVIDUAL, 
                                                                HAND_TRANSLATE_Y_RANGE_INDIVIDUAL, 
                                                                HAND_TRANSLATE_Z_RANGE_INDIVIDUAL, 
                                                                is_left_active_orig, is_right_active_orig)
            
            # 3. ì–‘ì† í•¨ê»˜ ì´ë™
            current_kps_3d = aug_translate_both_hands_together_v2(current_kps_3d, 
                                                                HAND_TRANSLATE_X_RANGE_TOGETHER, 
                                                                HAND_TRANSLATE_Y_RANGE_TOGETHER, 
                                                                HAND_TRANSLATE_Z_RANGE_TOGETHER, 
                                                                is_left_active_orig, is_right_active_orig)
            
            # 4. ë…¸ì´ì¦ˆ
            current_kps_3d = aug_add_noise_v2(current_kps_3d, KEYPOINT_JITTER_SIGMA_RANGE_V2, is_left_active_orig, is_right_active_orig)
            
            # 5. ì† í¬ê¸°
            current_kps_3d = aug_scale_hands_v2(current_kps_3d, HAND_SCALE_RANGE_V2, is_left_active_orig, is_right_active_orig)

            # 6. ì†ê°€ë½ ê¸¸ì´
            current_kps_3d = aug_scale_finger_lengths_v2(current_kps_3d, FINGER_LENGTH_SCALE_RANGE_V2, is_left_active_orig, is_right_active_orig)

            # 7. ì „ì²´ ìŠ¤ì¼€ì¼
            current_kps_3d = aug_scale_overall_v2(current_kps_3d, OVERALL_SCALE_RANGE, center_kp_idx=NOSE_IDX)

            # 8. ì‹œì  ë³€í™” (view_configsì—ì„œ yaw, pitch ë²”ìœ„ë¥¼ ê°€ì ¸ì™€ ëœë¤ ì ìš©)
            yaw_deg_vp = random.uniform(*config["yaw_range"])
            pitch_deg_vp = random.uniform(*config["pitch_range"])
            current_kps_3d = aug_change_viewpoint_v2(current_kps_3d, yaw_deg_vp, pitch_deg_vp, center_kp_idx=NOSE_IDX)

            # --- ìœ ë ¹ì† ìµœì¢… ì²˜ë¦¬: ì›ë³¸ì—ì„œ ë¹„í™œì„±ì´ì—ˆë˜ ì† ë°ì´í„° 0ìœ¼ë¡œ ë¦¬ì…‹ ---
            if not is_left_active_orig:
                current_kps_3d[:, LEFT_HAND_START_IDX : LEFT_HAND_START_IDX + HAND_KEYPOINTS_COUNT, :] = 0.0
            if not is_right_active_orig:
                current_kps_3d[:, RIGHT_HAND_START_IDX : RIGHT_HAND_START_IDX + HAND_KEYPOINTS_COUNT, :] = 0.0
            
            augmented_sequences_list.append(current_kps_3d.reshape(TARGET_SHAPE))
            total_augs_generated +=1
            
    print(f"ëª¨ë“  ì¦ê°• ìƒì„± ì™„ë£Œ (ì´ {total_augs_generated}ê°œ).")
    return augmented_sequences_list

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ìœ í‹¸ë¦¬í‹° (ê¸°ì¡´ê³¼ ë™ì¼) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
def valid(seq_flat, threshold=0.6):
    if seq_flat.shape != TARGET_SHAPE: print(f"âŒ Invalid shape: {seq_flat.shape}"); return False
    if (np.abs(seq_flat) < 1e-9).mean() >= threshold: print(f"âŒ Too many zeros"); return False
    return True

def save_sequences(label, sequences_list, base_path):
    path = os.path.join(base_path, label); os.makedirs(path, exist_ok=True)
    existing = [f for f in os.listdir(path) if f.startswith('group_') and f.endswith('.npy')]
    gid = max([int(f.split('_')[1][:-4]) for f in existing]) + 1 if existing else 0
    file_path = os.path.join(path, f'group_{gid:03d}.npy')
    try: np.save(file_path, np.stack([np.asarray(s) for s in sequences_list])); print(f"âœ… Saved {len(sequences_list)} to {file_path}")
    except Exception as e: print(f"âŒ Save error {file_path}: {e}")

def draw_landmarks_on_frame(frame, results):
    if results.pose_landmarks and results.pose_landmarks.landmark[POSE_ID_NOSE].visibility > 0.1:
        mp_drawing.draw_landmarks(image=frame, landmark_list=results.pose_landmarks,
            connections=[(mp_holistic.PoseLandmark.NOSE, mp_holistic.PoseLandmark.NOSE)],
            landmark_drawing_spec=mp_drawing.DrawingSpec(color=(80,110,10), thickness=2, circle_radius=2))
    if results.left_hand_landmarks: mp_drawing.draw_landmarks(frame, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)
    if results.right_hand_landmarks: mp_drawing.draw_landmarks(frame, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)

def put_text_on_frame(frame, text, y_offset=0, color=(0,255,0)):
    cv2.putText(frame, text, (10, 30 + y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2, cv2.LINE_AA)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ìº¡ì²˜ ë° ì²˜ë¦¬ ë©”ì¸ ë¡œì§ (ìˆ˜ì •ë¨) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
def capture_and_process():
    cap = cv2.VideoCapture(0)
    if not cap.isOpened(): raise RuntimeError("ì›¹ìº  Open ì‹¤íŒ¨")
    cv2.namedWindow(WINDOW_NAME)

    while True:
        label = input("\në¼ë²¨ ì…ë ¥ (or 'exit'): ").strip()
        if not label: print("ë¼ë²¨ ë¯¸ì…ë ¥"); continue
        if label.lower() == 'exit': break

        print(f"\n'{label}' ë¼ë²¨. ì›¹ìº  í™•ì¸. Enter: ë…¹í™” | ESC: ì·¨ì†Œ")
        action_cancelled, start_countdown = False, False
        while not start_countdown:
            ok, frame = cap.read()
            if not ok: print("âŒ ì›¹ìº  í”„ë ˆì„ Read ì‹¤íŒ¨"); action_cancelled=True; break
            frame = cv2.flip(frame,1); results = holistic.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
            draw_landmarks_on_frame(frame, results)
            put_text_on_frame(frame, f"Label: {label}",0,(255,255,0))
            put_text_on_frame(frame, "ENTER: Start", 30); put_text_on_frame(frame, "ESC: Cancel", 60, (0,0,255))
            cv2.imshow(WINDOW_NAME, frame)
            key = cv2.waitKey(1)&0xFF
            if key==13: start_countdown=True
            elif key==27: action_cancelled=True; break
        if action_cancelled: continue

        print("ìº¡ì²˜ ì¤€ë¹„...");
        for i in range(3,0,-1):
            ok,frame=cap.read();
            if not ok: print("âŒ ì›¹ìº  í”„ë ˆì„ Read ì‹¤íŒ¨(ì¹´ìš´íŠ¸ë‹¤ìš´)"); action_cancelled=True; break
            frame = cv2.flip(frame,1); results = holistic.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
            draw_landmarks_on_frame(frame, results)
            put_text_on_frame(frame, f"Starting in {i}...",0,(0,165,255))
            cv2.imshow(WINDOW_NAME, frame)
            if cv2.waitKey(1000)&0xFF==27: action_cancelled=True; break
        if action_cancelled: print(f"'{label}' ìº¡ì²˜ ì·¨ì†Œ"); continue

        print("ìº¡ì²˜ ì‹œì‘!");
        captured_frames_flat_data, interrupted = [], False
        target_wait_ms = max(1, int(1000 / (NUM_FRAMES / 2.5))) # ~2.5ì´ˆ ë™ì•ˆ NUM_FRAMES ìº¡ì²˜

        for f_num in range(NUM_FRAMES):
            ok,frame=cap.read()
            if not ok: print("âŒ ì›¹ìº  í”„ë ˆì„ Read ì‹¤íŒ¨(ìº¡ì²˜)"); interrupted=True; break
            results = holistic.process(cv2.cvtColor(cv2.flip(frame.copy(),1), cv2.COLOR_BGR2RGB))
            captured_frames_flat_data.append(extract_keypoints(results))
            display_frame = cv2.flip(frame.copy(),1); draw_landmarks_on_frame(display_frame, results)
            put_text_on_frame(display_frame,f"REC: {label} [{f_num+1}/{NUM_FRAMES}]",0,(0,0,255))
            cv2.imshow(WINDOW_NAME, display_frame)
            if cv2.waitKey(target_wait_ms)&0xFF==27: interrupted=True; print("ìº¡ì²˜ ì¤‘ë‹¨(ESC)"); break
        print(f"ìº¡ì²˜ ì™„ë£Œ ({len(captured_frames_flat_data)} í”„ë ˆì„).")

        if interrupted or len(captured_frames_flat_data) < NUM_FRAMES: print("ìº¡ì²˜ ë¯¸ì™„ë£Œ"); continue

        print("ì²˜ë¦¬ ë° ì¦ê°• ì‹œì‘...");
        original_sequence_flat = np.array(captured_frames_flat_data)
        interpolated_sequence_flat = interpolate_zeros(original_sequence_flat)
        if not valid(interpolated_sequence_flat, threshold=0.7): print("âŒ ë³´ê°„ í›„ ìœ íš¨ì„± ì‹¤íŒ¨"); continue
        print("ì›ë³¸ ìœ íš¨ì„± í†µê³¼.")

        save_sequences(label, [interpolated_sequence_flat.copy()], ORIGINAL_DATASET_PATH)

        try:
            # ìƒˆë¡œìš´ ì¦ê°• í•¨ìˆ˜ í˜¸ì¶œ
            augmented_sequences = generate_augmentations_v2(
                interpolated_sequence_flat, VIEW_CONFIGS_RANDOM_V2
            )
            if augmented_sequences: save_sequences(label, augmented_sequences, AUGMENTED_DATASET_PATH)
            else: print("ì¦ê°• ë°ì´í„° ì—†ìŒ.")
        except Exception as e: print(f"âŒ ì¦ê°• ì˜¤ë¥˜: {e}"); import traceback; traceback.print_exc(); continue

    cap.release(); cv2.destroyAllWindows(); holistic.close(); print("\nğŸ‰ í”„ë¡œê·¸ë¨ ì¢…ë£Œ")

if __name__ == '__main__':
    for path in [ORIGINAL_DATASET_PATH, AUGMENTED_DATASET_PATH]:
        if not os.path.exists(path): os.makedirs(path); print(f"í´ë” ìƒì„±: {path}")
    capture_and_process()